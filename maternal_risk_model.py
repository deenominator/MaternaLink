# -*- coding: utf-8 -*-
"""maternal_risk_model.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qqUMOyO5dHG6SxWCUGGv3fje54C8TMgu
"""

import os
os.listdir("/kaggle/input")

os.listdir("/kaggle/input/maternal-health-risk-data")

import pandas as pd

df = pd.read_csv("/kaggle/input/maternal-health-risk-data/Maternal Health Risk Data Set.csv")
df.head()

from sklearn.preprocessing import LabelEncoder
from sklearn.model_selection import train_test_split

# convert risk labels to numbers
le = LabelEncoder()
df["RiskLevel"] = le.fit_transform(df["RiskLevel"])

# separate inputs and output
X = df.drop("RiskLevel", axis=1)
y = df["RiskLevel"]

# split into training and testing data
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

print("Training data shape:", X_train.shape)
print("Testing data shape:", X_test.shape)

from sklearn.ensemble import RandomForestClassifier

model = RandomForestClassifier(random_state=42)
model.fit(X_train, y_train)

print("Model training complete.")

from sklearn.metrics import accuracy_score, classification_report

# make predictions on test data
y_pred = model.predict(X_test)

# check accuracy
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

# detailed performance
print("\nClassification Report:\n")
print(classification_report(y_test, y_pred))

import joblib

joblib.dump(model, "maternal_risk_model.pkl")

print("Model saved successfully.")

from sklearn.model_selection import GridSearchCV
from sklearn.ensemble import RandomForestClassifier

# parameter options to try
param_grid = {
    "n_estimators": [100, 200],
    "max_depth": [None, 5, 10],
    "min_samples_split": [2, 5],
}

rf = RandomForestClassifier(random_state=42)

grid_search = GridSearchCV(
    rf,
    param_grid,
    cv=5,
    scoring="accuracy",
    n_jobs=-1
)

grid_search.fit(X_train, y_train)

print("Best Parameters:", grid_search.best_params_)
print("Best Cross-Validation Accuracy:", grid_search.best_score_)

from sklearn.ensemble import GradientBoostingClassifier
from sklearn.model_selection import cross_val_score

gb = GradientBoostingClassifier(random_state=42)

scores = cross_val_score(gb, X, y, cv=5, scoring="accuracy")

print("Gradient Boosting CV Accuracy:", scores.mean())

from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.model_selection import cross_val_score

# Logistic Regression pipeline
log_model = Pipeline([
    ("scaler", StandardScaler()),
    ("clf", LogisticRegression(max_iter=1000))
])

log_scores = cross_val_score(log_model, X, y, cv=5, scoring="accuracy")
print("Logistic Regression CV Accuracy:", log_scores.mean())


# SVM pipeline
svm_model = Pipeline([
    ("scaler", StandardScaler()),
    ("clf", SVC())
])

svm_scores = cross_val_score(svm_model, X, y, cv=5, scoring="accuracy")
print("SVM CV Accuracy:", svm_scores.mean())

from sklearn.model_selection import RandomizedSearchCV
from sklearn.ensemble import RandomForestClassifier
import numpy as np

param_dist = {
    "n_estimators": np.arange(100, 500, 50),
    "max_depth": [None, 5, 10, 15, 20],
    "min_samples_split": [2, 5, 10],
    "min_samples_leaf": [1, 2, 4],
    "bootstrap": [True, False]
}

rf = RandomForestClassifier(random_state=42)

random_search = RandomizedSearchCV(
    rf,
    param_distributions=param_dist,
    n_iter=30,
    cv=5,
    scoring="accuracy",
    n_jobs=-1,
    random_state=42
)

random_search.fit(X_train, y_train)

print("Best Parameters:", random_search.best_params_)
print("Best CV Accuracy:", random_search.best_score_)

import joblib

best_model = random_search.best_estimator_

joblib.dump(best_model, "maternal_risk_model_final.pkl")

print("Final model saved successfully.")

import joblib

loaded_model = joblib.load("maternal_risk_model_final.pkl")

print("Model loaded successfully!")

print("Sample prediction:", loaded_model.predict(X_test[:3]))